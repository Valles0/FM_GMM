{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1915b76",
   "metadata": {},
   "source": [
    "# Flow Matching sur des mélanges de Gaussiennes (GMM)\n",
    "\n",
    "Nous faisons quelques expériences sur le Flow Matching en utilisant comme distributions de départ et d'arrivée des mélanges de gaussiennes. Nous nous plaçons dans le cadre de *Stochastic Interpolants*, plus rigoureux que celui établi par Méta, qui ne comprend d'ailleurs pas ce cas (une des distributions devant avoir une densité par rapport à la mesure de Lebesgue à support compact). Cependant, les démonstrations de l'article sont valables lorsqu'interpolation est accompagnée d'un \"lissage gausssien\" du chemin de probabilités, représenté par la fonction $\\gamma$ dans l'article. Nous adaptons donc les hypothèses et les démonstrations à notre cas.\n",
    "\n",
    "\n",
    "## Stochastic Interpolants sans le lissage gaussien\n",
    "\n",
    "**On ne considère que des distributions de probabilités $p$ sur un $\\mathbb{R}^k$ ($k\\in \\mathbb{N}^*$) à densité par rapport à la mesure de Lebesgue, dont on note aussi (abusivement) $p$ la densité.**\n",
    "\n",
    "Soient $p_0$ et $p_1$ deux distributions de probabilités sur $\\mathbb{R}^d$, $\\Pi$ un couplage de $(p_0, p_1)$.  On veut transporter $p_0$ vers $p_1$.\n",
    "\n",
    "Soit également\n",
    " $$I : (t, x, y)\\in [0,1]\\times \\mathbb{R}^d \\times \\mathbb{R}^d \\mapsto I(t,x,y)\\in\\mathcal{R}^d $$ \n",
    " une fonction $\\mathcal{C}^2$ de $t$, telle que pour tout $t\\in [0,1]$, $I(t, \\cdot, \\cdot)$ est aussi $\\mathcal{C}^2$, $I(0,x,y)=$ et $I(1,x,y)=y$, et avec $C_1 >0$ tel que\n",
    "$$\\forall (t,x,y) \\in [0,1]\\times \\times \\mathbb{R}^d, \\;\\; |\\partial_t I(t,x,y)| \\leq C_1 |x-y|.$$\n",
    "\n",
    "#### Hypothèses supplémentaires\n",
    "On suppose $p_0, p_1$ sont de support $\\mathbb{R}^d$ et de classe $\\mathcal{C}^2$, que \n",
    "$$ \\mathbb{E}_{X_0\\sim p_0}\\left[ |\\nabla \\log p_0(X_0) |^2 \\right]<\\infty \\; \\text{ et } \\mathbb{E}_{X_1\\sim p_1}\\left[ |\\nabla \\log p_1(X_1)|^2 \\right] < \\infty$$\n",
    "et qu'on dispose de $M_1, M_2 >0$ tels que\n",
    "$$\\forall t\\in[0,1],\\;\\;  \\mathbb{E}_{(X_0,X_1)\\sim \\Pi}\\left[ |\\partial_t I(t,X_0, X_1)|^4 \\right] \\leq M_1, \\;\\; \\mathbb{E}_{(X_0,X_1)\\sim \\Pi}\\left[ |\\partial_t^2 I(t,X_0, X_1)|^2 \\right] \\leq M_2.$$\n",
    "\n",
    "**Nous ne considérerons ici que des interpolations affines : $I(t,x,y) = b_t x + a_t y$ où $a, b : [0,1]\\to [0,1] $ sont des fonctions $\\mathcal{C}^2$ avec $a_0 = b_1 = 0$, $a_1=b_0=1$ et $\\dot{a_t}>0$, $\\dot{b_t}<0$.** \n",
    "Il faut alors : \n",
    "$$\\forall (t,x,y) \\in [0,1]\\times \\times \\mathbb{R}^d, \\;\\; |\\dot{b_t}x+\\dot{a_t}y| \\leq C_1 |x-y|$$\n",
    "ainsi que\n",
    "$$\\forall t\\in[0,1],\\;\\;  \\mathbb{E}_{(X_0,X_1)\\sim \\Pi}\\left[ |\\dot{b_t}X_0+\\dot{a_t}X_1)|^4 \\right] \\leq M_1, \\;\\; \\mathbb{E}_{(X_0,X_1)\\sim \\Pi}\\left[ |\\ddot{b_t}X_0+\\ddot{a_t}X_1)|^2 \\right] \\leq M_2.$$\n",
    "\n",
    "\n",
    "#### Construction du champ de vitesse\n",
    "\n",
    "Posons, pour $t\\in [0,1]$, $X_t = I(t, X_0, X_1)$, où $(X_0,X_1)\\sim \\Pi$. La distribution de $X_t$ admet une densité, notée $p(t,\\cdot)$ ou de façon équivalent $p_t$. Posons ensuite $u(t,x)$ ou $u_t(x)$ la valeur $\\mathbb{E}\\left[\\partial_t I(t, X_0, X_1) \\vert I(t, X_0, X_1) = x\\right]\\in\\mathbb{R}^d$. \n",
    "Alors $p$ vérifie l'équation de continuité associée au champ de vitesse $u$ \n",
    "$$\\forall t \\in [0,1], \\; x\\in\\mathbb{R}^d, \\;\\;\\; \\partial_t p_t(x) = -\\text{div}(u_t p_t)(x),$$\n",
    "et $p_t$ s'obtient en fait comme mesure image (push-forward) de $p_0$ par le flot engendré par $u$.\n",
    "On appelle $u$ le champ de vitesse, et $(p_t)$ le chemin de probabilités.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc8d610",
   "metadata": {},
   "source": [
    "## Gaussiennes : formules explicites\n",
    "### Simples Gaussiennes\n",
    "Supposons $(X_0, X_1) \\sim \\mathcal{N}(m, \\Sigma)$, où $m = \\begin{bmatrix} m_0 \\\\ m_1 \\end{bmatrix} \\in \\mathbb{R}^{2d}$ et \n",
    "$\\Sigma = \\begin{bmatrix} \\Sigma_{00} & \\Sigma_{01}  \\\\  \\Sigma_{10} & \\Sigma_{11} \\end{bmatrix} \\in \\mathbb{R}^{2d\\times 2d}$.\n",
    "\n",
    "Posons alors $A_t = \\begin{bmatrix} b_t Id & a_t Id  \\\\  \\dot{b_t} Id & \\dot{a_t} Id \\end{bmatrix} \\in \\mathbb{R}^{2d\\times 2d}$.\n",
    "Le vecteur $(\\dot{X_t}, X_t)= (\\dot{b_t} X_0 + \\dot{a_t} X_1,b_t X_0 + a_t X_1 )$ est alors gaussien, d'espérance $m^t = A_t m$ et de matrice de covariance $\\Sigma^t = A \\Sigma A^T$.\n",
    "\n",
    "Par conditionnement gaussien, \n",
    "\\begin{align*}\n",
    "u_t(x) &= \\mathbb{E}(\\dot{X_t} | X_t = x) \\\\\n",
    "&= m^t_1 + \\Sigma^t_{10}(\\Sigma^t_{00})^{-1}(x-m^t_0 )   \\\\\n",
    "&= \\dot{b_t} m_0 + \\dot{a_t} m_1 +  (b_t \\dot{b_t} \\Sigma_{00} + b_t \\dot{a_t} \\Sigma_{10} + a_t \\dot{b_t} \\Sigma_{01} + a_t \\dot{a_t}\\Sigma_{11})(b_t^2 \\Sigma_{00} + a_t b_t (\\Sigma_{01}+\\Sigma_{10}) + a_t^2 \\Sigma_{11})^{-1} (x- b_t m_0 - a_t m_1)  \\\\\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Avec les schedulers habituels de Flow Matching \n",
    "$$ \\forall t\\in[0,1], \\;\\; \\; a_t = t, \\;\\; b_t=1-t, $$\n",
    "on obtient :\n",
    "\\begin{align*}\n",
    "u_t(x) &= - m_0 +  m_1 +  (-(1-t) \\Sigma_{00} + (1-t) \\Sigma_{01} -t \\Sigma_{10} + t \\Sigma_{11}) ((1-t)^2 \\Sigma_{00} + t (1-t) (\\Sigma_{01}+\\Sigma_{10}) + t^2 \\Sigma_{11})^{-1} (x- (1-t) m_0 - t m_1) \\\\\n",
    "\\end{align*}\n",
    "A REECRIRE POUR SIMPLIFIER\n",
    "\n",
    "\n",
    "### Mélanges de gaussiennes\n",
    "\n",
    "Supposons maintenant  $(X_0, X_1) \\sim \\sum_{k=1}^L \\pi_k \\mathcal{N}(m^k, \\Sigma^k)$, où $m^k = \\begin{bmatrix} m^k_0 \\\\ m^k_1 \\end{bmatrix} \\in \\mathbb{R}^{2d}$ et \n",
    "$\\Sigma^k = \\begin{bmatrix} \\Sigma^k_{00} & \\Sigma^k_{01}  \\\\  \\Sigma^k_{10} & \\Sigma^k_{11} \\end{bmatrix} \\in \\mathbb{R}^{2d\\times 2d}$. Soient $K$ variable aléatoire à valeurs dans $\\{1, \\cdots, L\\}$, avec $\\mathbb{P}(K=i)= \\pi_i$. Rappelons qu'on peut peut décomposer la loi de $(X_0, X_1)$ comme \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Notons \n",
    "$$v_t^k(x) = \\dot{b_t} m^k_0 + \\dot{a_t} m^k_1 +  (b_t \\dot{b_t} \\Sigma^k_{00} + b_t \\dot{a_t} \\Sigma^k_{10} + a_t \\dot{b_t} \\Sigma^k_{01} + a_t \\dot{a_t}\\Sigma^k_{11})(b_t^2 \\Sigma^k_{00} + a_t b_t (\\Sigma^k_{01}+\\Sigma^k_{10}) + a_t^2 \\Sigma^k_{11})^{-1} (x- b_t m^k_0 - a_t m^k_1)$$\n",
    "le champ de vitesse associé à la $k^e$ composante de notre GMM.\n",
    "\n",
    "Or, les propriétés de l'espérance conditionnelle font que\n",
    "\\begin{align*}\n",
    "u_t(x) &= \\mathbb{E}(\\dot{X_t} | X_t = x)\\\\\n",
    "&= \\mathbb{E}(\\mathbb{E}(\\dot{X_t} | X_t = x, K=k)|X_t = x) \\\\\n",
    "&= \\sum_{k=1}^L \\mathbb{P}(K=k|X_t =x) v_t^k(x) \\\\\n",
    "&= \\sum_{k=1}^L \\alpha_t^k(x) v_t^k(x) \\\\\n",
    "\\end{align*} \n",
    "où $\\alpha_t^k(x)=\\mathbb{P}(K=k|X_t =x)= \\frac{\\pi_k \\mathcal{N}(x ; A_t m^k, A_t \\Sigma^k A_t^T)}{\\sum_{i=1}^L \\pi_i \\mathcal{N}(x ; A_t m^i, A_t \\Sigma^i A_t^T)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d5816d",
   "metadata": {},
   "source": [
    "## CODE\n",
    "\n",
    "#### Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd1833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import vmap\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import time\n",
    "from torch import nn, Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ca014",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nice defaults\n",
    "%matplotlib inline\n",
    "mpl.rcParams['axes.grid']  = True\n",
    "mpl.rcParams['axes.grid.which']  = 'both'\n",
    "mpl.rcParams['xtick.minor.visible']  = True\n",
    "mpl.rcParams['ytick.minor.visible']  = True\n",
    "mpl.rcParams['xtick.minor.visible']  = True\n",
    "mpl.rcParams['axes.facecolor'] = 'white'\n",
    "mpl.rcParams['grid.color'] = '0.8'\n",
    "mpl.rcParams['grid.alpha'] = '0.5'\n",
    "mpl.rcParams['figure.figsize'] = (8, 4)\n",
    "mpl.rcParams['figure.titlesize'] = 12.5\n",
    "mpl.rcParams['font.size'] = 12.5\n",
    "mpl.rcParams['legend.fontsize'] = 12.5\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeaf211",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print('Using GPU.')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('Using the cpu. No GPU!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(17)\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8cbb62",
   "metadata": {},
   "source": [
    "### Créations des gaussiennes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53bd9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_random_covs(N: int, d: int):\n",
    "    Cs = torch.zeros(N, d, d, device=device)\n",
    "    for ii in range(N):\n",
    "        C = torch.randn(d, d, device=device)/np.sqrt(d)\n",
    "        Cs[ii] = (C.T @ C + 0.5*torch.eye(d, device=device)) \n",
    "    return Cs\n",
    "\n",
    "# Crée une moyenne aléatoire \n",
    "def setup_random_means(N: int, d: int, scale: float):\n",
    "    return scale*torch.randn((N, d),device=device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
